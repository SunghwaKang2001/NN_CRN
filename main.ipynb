{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03f15253",
   "metadata": {},
   "source": [
    "<H1>How to use NN_CRN\n",
    "\n",
    "<H5>\n",
    "Smoothed ReLU : define n1, n2, n3(number of nodes of each layer)/H(smoothing parameter)/init_mu, init_sigma(initialization parameters for the layer)/dt(size of timestep)/k_u(learning rate)/noise/timelen(how many timesteps in one iteration)  \n",
    "\n",
    "Leaky ReLU : define n1, n2, n3/alpha, beta(Derivative of Leaky ReLU on positive domain and negative domain, respectively)/init_mu, init_sigma, dt, k_u, noise, timelen\n",
    "\n",
    "Each network has two functions : run, run_for_single_data  \n",
    "\n",
    "run(label_x, label_y, test_x, test_y, noise_controller, epoch, N, dataset_type) : run for the train dataset(label_x, label_y) and validation dataset(test_x, test_y) for given epoch. N means the size of train dataset. Dataset type is 'XOR' or 'iris' or 'MNIST' or 'half_sine'.(But accuracy data is useless for half_sine dataset) Noise controller is 0 when noise is not used. It is 1 when noise is added on reaction rate. It is 2 when noise is added on each neural network layer. It is 3 when noise is added on input data chemical species. This function returns train loss, validation loss, accuracy, and history of parameters(weight and bias).\n",
    "\n",
    "run_for_some_data(label_x, label_y, noise_controller, run_num, N) : Execute training for run_num iteration, and returns history of Y value, W1(0,0) value, and derivative of activation function as its input for each layers.\n",
    "\n",
    "We also provide some visualization tools for each dataset in visualization.py module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64be869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import NN_CRN\n",
    "import numpy as np\n",
    "import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6666c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Network = NN_CRN.NN_CRN_smoothed_ReLU(n1=2, n2=10, n3=1, H=3, init_mu=0, init_sigma=0.1, dt=0.1, k_u=0.01, noise=0.1, timelen=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8c4ccd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_x, label_y, test_x, test_y, N = datasets.XOR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b1aee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, validation_loss, accuracy, params = Network.run(label_x = label_x, label_y = label_y, test_x = test_x, test_y = test_y, noise_controller = 0, epoch = 9000, N = N, dataset_type = 'XOR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fb589b",
   "metadata": {},
   "source": [
    "Visualization functions\n",
    "\n",
    "1. XOR_smoothed_ReLU(Network, train_loss, accuracy, params, N, epoch, noise_controller)/XOR_Leaky_ReLU(Network, train_loss, accuracy, params, N, epoch, noise_controller) : returns train loss graph, accuracy graph, training process visualization\n",
    "\n",
    "2. sine_smoothed_ReLU(Network, train_loss, noise_controller)/sine_Leaky_ReLU(Network, train_loss, noise_controller) : returns train loss graph\n",
    "\n",
    "3. MNIST_smoothed_ReLU(Network, train_loss, validation_loss, accuracy, N, epoch, noise_controller)/MNIST_Leaky_ReLU(Network, train_loss, validation_loss, accuracy, N, epoch, noise_controller) : returns train loss graph, accuracy graph, classification result\n",
    "\n",
    "4. iris_smoothed_ReLU(Network, train_loss, validation_loss, accuracy, N, epoch, noise_controller)/iris_Leaky_ReLU(Network, train_loss, validation_loss, accuracy, N, epoch, noise_controller) : returns train loss graph, accuracy graph, classification result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ad4760",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization.XOR_smoothed_ReLU(Network, train_loss, accuracy, params, N=N, epoch=9000, noise_controller=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56d7cf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for Figure 4, Figure 6\n",
    "Yvals, w2vals, Dz1vals, Dz0vals = Network.run_for_some_data(label_x = label_x, label_y = label_y, noise_controller = 0, run_num = 4, N = N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c00775b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Yvals, 'r')\n",
    "plt.title('Y value')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('Y')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(w2vals, 'r')\n",
    "plt.title('$W^1_{11}$ value')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('$W^1_{11}$')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(Dz1vals,'r')\n",
    "plt.title('$\\\\frac{d\\sigma}{dz^1_0}$ value')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('$\\\\frac{d\\sigma}{dz^1_0}$')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(Dz0vals,'r')\n",
    "plt.title('$\\\\frac{d\\sigma}{dz^0_0}$ value')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('$\\\\frac{d\\sigma}{dz^0_0}$')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e6963b",
   "metadata": {},
   "source": [
    "<H2>\n",
    "Example : Mean error about error rate(Figure 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4bbda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_train_loss = [[],[],[],[]]\n",
    "avg_val_loss = [[],[],[],[]]\n",
    "for k in range(4) : \n",
    "    N1 = NN_CRN.NN_CRN_Leaky_ReLU(n1=1, n2=10, n3=1,alpha=1,beta=0.3, init_mu=0, init_sigma=0.1, dt=0.1, k_u=0.001, noise=0.02, timelen=50)\n",
    "    N2 = NN_CRN.NN_CRN_Leaky_ReLU(n1=1, n2=10, n3=1,alpha=1,beta=0.3, init_mu=0, init_sigma=0.1, dt=0.1, k_u=0.001, noise=0.04, timelen=50)\n",
    "    N3 = NN_CRN.NN_CRN_Leaky_ReLU(n1=1, n2=10, n3=1,alpha=1,beta=0.3, init_mu=0, init_sigma=0.1, dt=0.1, k_u=0.001, noise=0.06, timelen=50)\n",
    "    N4 = NN_CRN.NN_CRN_Leaky_ReLU(n1=1, n2=10, n3=1,alpha=1,beta=0.3, init_mu=0, init_sigma=0.1, dt=0.1, k_u=0.001, noise=0.08, timelen=50)\n",
    "    N5 = NN_CRN.NN_CRN_Leaky_ReLU(n1=1, n2=10, n3=1,alpha=1,beta=0.3, init_mu=0, init_sigma=0.1, dt=0.1, k_u=0.001, noise=0.1, timelen=50)\n",
    "    N6 = NN_CRN.NN_CRN_Leaky_ReLU(n1=1, n2=10, n3=1,alpha=1,beta=0.3, init_mu=0, init_sigma=0.1, dt=0.1, k_u=0.001, noise=0.12, timelen=50)\n",
    "    N_array = [N1,N2,N3,N4,N5,N6]\n",
    "    for i in range(6) : \n",
    "        train_loss, validation_loss, accuracy, params = N_array[i].run(label_x,label_y,test_x,test_y,noise_controller=1,epoch=100,N=N,dataset_type='sine')\n",
    "        avg_train_loss[k].append(np.mean([train_loss[(10-j)*(N*10)-1] for j in range(10)]))\n",
    "        avg_val_loss[k].append(np.mean([validation_loss[(10-j)*(N*10)-1] for j in range(10)]))\n",
    "\n",
    "plt.scatter([0.02,0.04,0.06,0.08,0.1,0.12],avg_train_loss[0],c='r')\n",
    "plt.scatter([0.02,0.04,0.06,0.08,0.1,0.12],avg_train_loss[1],c='r')\n",
    "plt.scatter([0.02,0.04,0.06,0.08,0.1,0.12],avg_train_loss[2],c='r')\n",
    "plt.scatter([0.02,0.04,0.06,0.08,0.1,0.12],avg_train_loss[3],c='r')\n",
    "plt.scatter([0.02,0.04,0.06,0.08,0.1,0.12],avg_val_loss[0],c='b')\n",
    "plt.scatter([0.02,0.04,0.06,0.08,0.1,0.12],avg_val_loss[1],c='b')\n",
    "plt.scatter([0.02,0.04,0.06,0.08,0.1,0.12],avg_val_loss[2],c='b')\n",
    "plt.scatter([0.02,0.04,0.06,0.08,0.1,0.12],avg_val_loss[3],c='b')\n",
    "plt.title('Leaky ReLU mean error about noise')\n",
    "plt.ylim(-0.05,0.2)\n",
    "plt.xlabel('Noise level')\n",
    "plt.ylabel('mean error')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
